{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "The standard neural network we looked at in the previous lesson takes in a vector as input thus a flattened image could be passed in as input and used for classification problems successfully. But this is not the best way to do it. If you think about an image, the spatial relations between the different pixels is an important piece of information when determening what the image is. If we scrambled the pixels of an image, it would be much harder to determine what is in it. This is basically what we are doing when we flatten the image and use standard NNs as the order of pixels which we use in the input vector to the network does not affect the performance of the NN. We are losing the information of the spatial relations of the pixels.\n",
    "\n",
    "Convolutional neural networks solve this very problem. Rather than performing a matrix multiplication, a convolution operation is performed which can take in a 2d input and give a 2d output hence keep the information about the spatial relations of the pixels. This greatly increases their performance on image and video processing tasks.\n",
    "\n",
    "In the convolution proccess, you have a filter which you start on the top left side of the image and slide across the whole image, taking a dot product between the values of the filter and pixel values of the image. Bear in mind that colour images have three channels so your filter may be 3-d so you take the dot product across a 3d-volume. Each dot product corresponds to a single activation value in a 2-d matrix of neurons which corresponds to a single layer in the output. This gives each activation value in the next layer an *activation region*. \n",
    "\n",
    "The animation below shows how a 1x3x3 filter is applied to a 1x5x5 image. Notice how the filter has high output values when there is an X shape in the input image. This is because the values of the filter are such that it is performing pattern matching for the X shape.\n",
    "\n",
    "![](cnn.gif)\n",
    "\n",
    "For a long time, operations like this were used in computer vision to find different patterns in images with the engineers having to manually tune the values of the filters to perform the required function. The only difference now is that we apply an activation such as Relu or Sigmoid at each layer and after setting up the structure of the network, we initialize the filter values randomly before using gradient descent to automatically tune the values of the filters.\n",
    "We can also apply pooling operations to subsample the output at each layer therefore reducing the number of parameters that need to be learned for the next convolution operation.\n",
    "\n",
    "![](cnn.png)\n",
    "\n",
    "Just like before, each layer in the whole network learns higher level abstract features from the inputs. In CNNs the features are even more interpretable as the output of each layer is 2d so can be viewed as an image.\n",
    "\n",
    "## Implementation\n",
    "we will be implementing a CNN which can take as input a 1x28x28 black and white images of hand-written digits and classifying it into which digit the image depicts. We have a dataset of 60,000 images and their corresponding labels to train on and 10,000 to test on. This is called the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the MNIST training and test sets from the default PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(root='data/',\n",
    "                                  transform=transforms.ToTensor(),\n",
    "                                  train=True,\n",
    "                                  download=True,\n",
    "                               )\n",
    "\n",
    "test_data = datasets.MNIST(root='data/',\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           train=False,\n",
    "                            )\n",
    "\n",
    "#show our first training data item\n",
    "print(training_data[0])\n",
    "plt.imshow(training_data[0][0][0], cmap='gray_r')\n",
    "plt.show()\n",
    "\n",
    "print('Number of training examples:', len(training_data))\n",
    "print('Number of test examples:', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader generator from our datasets. Dataloaders generate random samples from the training set and the test set (not randomly from the test set as it doesn't affect our results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# dataloader is a generator that can sample from the training set\n",
    "training_samples = torch.utils.data.DataLoader(dataset=training_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True)\n",
    "\n",
    "test_samples = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model calss, it is a 2 layer convnet with a fully connected layer at the end to map it to 10 output neurons, each corresopnding to the probability of the input image being a particular digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convnet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            # conv2d(in_channels, out_channels, kernel_size)\n",
    "            # in_channels is the number of layers which it takes in (i.e.num color streams in 1st layer)\n",
    "            # out_channels is the number of different filters that we use\n",
    "            # kernel_size is the depthxwidthxheight of the kernel#\n",
    "            # stride is how many pixels we shift the kernel by each time\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=5, stride=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=5, stride=1)\n",
    "        self.dense1 = torch.nn.Linear(25600, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu((self.conv1(x)))\n",
    "        x = F.relu((self.conv2(x))).view(x.shape[0], -1) #flatten output ready for fully connected layer\n",
    "        x = F.softmax(self.dense1(x), dim=1) #fully connected layer with softmax activation\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper-parameters, cost function, optimizer and instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001 #learning rate\n",
    "epochs = 1 #number of epochs\n",
    "\n",
    "cnn = convnet() #instantiate model\n",
    "criterion = torch.nn.CrossEntropyLoss() #cost function\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=lr) #optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training loop and train for the number of epochs. Since our dataset is huge and an epoch takes a while to complete, we will plot our cost every batch rather than every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    #for plotting cost per batch\n",
    "    costs = []\n",
    "    plt.ion()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.show()\n",
    "    ax.set_xlabel('Batch')\n",
    "    ax.set_ylabel('Cost')\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for i, (x, y) in enumerate(training_samples):\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            h = cnn.forward(x) #calculate hypothesis\n",
    "            cost = criterion(h, y) #calculate cost\n",
    "            \n",
    "            optimizer.zero_grad() #zero gradients\n",
    "            cost.backward() # calculate derivatives of values of filters\n",
    "            optimizer.step() #update parameters\n",
    "\n",
    "            costs.append(cost.data[0])\n",
    "            ax.plot(costs, 'b')\n",
    "            fig.canvas.draw()\n",
    "\n",
    "            print('Epoch', e, '\\tBatch', i, '\\tCost', cost.data[0])\n",
    "\n",
    "train(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print('Started evaluation...')\n",
    "    cnn.eval() #put model into evaluation mode\n",
    "    \n",
    "    #calculate the accuracy of our model over the whole test set in batches\n",
    "    correct = 0\n",
    "    for x, y in test_samples:\n",
    "        x, y = Variable(x), y\n",
    "        h = cnn.forward(x)\n",
    "        pred = h.data.max(1)[1]\n",
    "        correct += pred.eq(y).sum()\n",
    "    return correct/len(test_data)\n",
    "\n",
    "acc = test()\n",
    "print('Test accuracy: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
